{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from refer import REFER\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Refer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset refclef into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=2.95s)\n"
     ]
    }
   ],
   "source": [
    "data_root = './data'  # contains refclef, refcoco, refcoco+, refcocog and images\n",
    "dataset = 'refclef'\n",
    "splitBy = 'unc'\n",
    "refer = REFER(data_root, dataset, splitBy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats about the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset refclef unc contains: \n",
      "130364 expressions for 99296 refs in 19997 images.\n",
      "\n",
      "Among them:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m ref_ids \u001b[38;5;241m=\u001b[39m refer\u001b[38;5;241m.\u001b[39mgetRefIds(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m     25\u001b[0m ref_id \u001b[38;5;241m=\u001b[39m ref_ids[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 26\u001b[0m ref \u001b[38;5;241m=\u001b[39m \u001b[43mrefer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadAnns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattributes: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ref[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/kuliah/skripsi/refer2/refer_python3_2024/refer.py:218\u001b[0m, in \u001b[0;36mREFER.loadAnns\u001b[0;34m(self, ann_ids)\u001b[0m\n\u001b[1;32m    216\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAnns[ann_id] \u001b[38;5;28;01mfor\u001b[39;00m ann_id \u001b[38;5;129;01min\u001b[39;00m ann_ids]\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(ann_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(ann_ids) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39municode_:\n\u001b[0;32m--> 218\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAnns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mann_ids\u001b[49m\u001b[43m]\u001b[49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# print stats about the given dataset\n",
    "print (('dataset %s %s contains: ') % (dataset, splitBy))\n",
    "ref_ids = refer.getRefIds()\n",
    "image_ids = refer.getImgIds()\n",
    "print(( '%s expressions for %s refs in %s images.') % (len(refer.Sents), len(ref_ids), len(image_ids)))\n",
    "\n",
    "print ('\\nAmong them:')\n",
    "if dataset == 'refclef':\n",
    "    if splitBy == 'unc':\n",
    "        splits = ['train', 'val', 'testA', 'testB', 'testC']\n",
    "    else:\n",
    "        splits = ['train', 'val', 'test']\n",
    "elif dataset == 'refcoco':\n",
    "    splits = ['train', 'val', 'test']\n",
    "elif dataset == 'refcoco+':\n",
    "    splits = ['train', 'val', 'test']\n",
    "elif dataset == 'refcocog':\n",
    "    splits = ['train', 'val']  # we don't have test split for refcocog right now.\n",
    "    \n",
    "for split in splits:\n",
    "    ref_ids = refer.getRefIds(split=split)\n",
    "    # print('%s refs are in split %s.' % (len(ref_ids), split))\n",
    "    # print all annotation\n",
    "    ref_ids = refer.getRefIds(split=split)\n",
    "    ref_id = ref_ids[2]\n",
    "    ref = refer.loadAnns(ref_id)\n",
    "    print('attributes: %s' % ref['attributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get annotation IDs for a specific image ID\n",
    "image_id = 2  # Replace with a valid image ID\n",
    "ann_ids = refer.getAnnIds(image_ids=[image_id])\n",
    "\n",
    "# Load the annotations using the obtained annotation IDs\n",
    "annotations = refer.loadAnns(ann_ids)\n",
    "\n",
    "# Print the annotations\n",
    "for ann in annotations:\n",
    "    print(ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Refered Object and its Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_id [29187] (ann_id 27624_8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# randomly sample one ref\n",
    "ref_ids = refer.getRefIds()\n",
    "ref_id = ref_ids[np.random.randint(0, len(ref_ids))]\n",
    "ref = refer.Refs[ref_id]\n",
    "print('ref_id [%s] (ann_id %s)' % (ref_id, refer.refToAnn[ref_id]['id']))\n",
    "# show the segmentation of the referred object\n",
    "plt.figure()\n",
    "# refer.showRef(ref, seg_box='seg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or show the bounding box of the referred object\n",
    "# refer.showRef(ref, seg_box='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_id[101470]: sand bottom\n"
     ]
    }
   ],
   "source": [
    "# let's look at the details of each ref\n",
    "for sent in ref['sentences']:\n",
    "    print('sent_id[%s]: %s' % (sent['sent_id'], sent['sent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_id [49564] (ann_id 48_7)\n",
      "{'sent_ids': [66159], 'ann_id': '48_7', 'ref_id': 49564, 'image_id': 48, 'split': 'train', 'sentences': [{'tokens': ['blue', 'shirt', 'bottom', 'right'], 'raw': 'blue shirt bottom right', 'sent_id': 66159, 'sent': 'blue shirt bottom right'}], 'category_id': 120}\n"
     ]
    }
   ],
   "source": [
    "ref_id = ref_ids[np.random.randint(0, len(ref_ids))]\n",
    "ref = refer.Refs[ref_id]\n",
    "print('ref_id [%s] (ann_id %s)' % (ref_id, refer.refToAnn[ref_id]['id']))\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white area over between the two guys on the left\n"
     ]
    }
   ],
   "source": [
    "# random sample one ref\n",
    "\n",
    "tm = False\n",
    "while not tm:\n",
    "    ref_id = ref_ids[np.random.randint(0, len(ref_ids))]\n",
    "    ref = refer.Refs[ref_id]\n",
    "    words_length = len(ref['sentences'][0]['tokens'])\n",
    "    if words_length > 3: # only select the refs with more than 3 words\n",
    "        print(ref['sentences'][0]['sent'])\n",
    "        tm = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample output of refer dataset:\n",
    "{'sent_ids': [0], 'ann_id': '19135_1', 'ref_id': 0, 'image_id': 19135, 'split': 'train', 'sentences': [{'tokens': ['sky'], 'raw': 'sky', 'sent_id': 0, 'sent': 'sky'}], 'category_id': 60}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert sentences data into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "coffeescript"
    }
   },
   "outputs": [],
   "source": [
    "# {'sent_ids': [0], 'ann_id': '19135_1', 'ref_id': 0, 'image_id': 19135, 'split': 'train', 'sentences': [{'tokens': ['sky'], 'raw': 'sky', 'sent_id': 0, 'sent': 'sky'}], 'category_id': 60} make this json into of sentence id, annotate id, ref id, image id, split, token , raw, sent id, sent, category id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./data/refclef/refclef_unc_flattened.csv\n",
      "  sent_ids_list   ann_id  ref_id  image_id  split  category_id  \\\n",
      "0             0  19135_1       0     19135  train           60   \n",
      "1             1  19135_2       1     19135  train          235   \n",
      "2             2  23412_4       2     23412  train          258   \n",
      "3             3  23412_1       3     23412  train          160   \n",
      "4             4  23412_2       4     23412  train          120   \n",
      "\n",
      "                       tokens                         raw  sent_id  \\\n",
      "0                         sky                         sky        0   \n",
      "1                      statue                      statue        1   \n",
      "2  anywhere,except,the,people  anywhere except the people        2   \n",
      "3             person,in,front             person in front        3   \n",
      "4  person,all,the,way,in,back  person all the way in back        4   \n",
      "\n",
      "                         sent  \n",
      "0                         sky  \n",
      "1                      statue  \n",
      "2  anywhere except the people  \n",
      "3             person in front  \n",
      "4  person all the way in back  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os.path as osp\n",
    "\n",
    "def convert_refer_to_df(data_root, dataset='refcoco', splitBy='unc'):\n",
    "    \"\"\"\n",
    "    Convert REFER data structure to a pandas DataFrame and save as CSV\n",
    "    \n",
    "    Args:\n",
    "        data_root: Path to the data directory\n",
    "        dataset: Dataset name (default: 'refcoco')\n",
    "        splitBy: Split by (default: 'unc')\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing flattened REFER data\n",
    "    \"\"\"\n",
    "    # Path to the pickle file\n",
    "    ref_file = osp.join(data_root, dataset, f'refs({splitBy}).p')\n",
    "    \n",
    "    # Load the pickle file in binary mode\n",
    "    refs = pickle.load(open(ref_file, 'rb'))\n",
    "    \n",
    "    # Create a list to hold flattened data\n",
    "    flattened_data = []\n",
    "    \n",
    "    # Iterate through each ref\n",
    "    for ref in refs:\n",
    "        # For each sentence in the ref\n",
    "        for sent in ref['sentences']:\n",
    "            # Create a flattened entry\n",
    "            entry = {\n",
    "                'sent_ids_list': ref['sent_ids'],  # This will be a list\n",
    "                'ann_id': ref['ann_id'],\n",
    "                'ref_id': ref['ref_id'],\n",
    "                'image_id': ref['image_id'],\n",
    "                'split': ref['split'],\n",
    "                'category_id': ref['category_id'],\n",
    "                'tokens': sent['tokens'],  # This will be a list\n",
    "                'raw': sent['raw'],\n",
    "                'sent_id': sent['sent_id'],\n",
    "                'sent': sent['sent']\n",
    "            }\n",
    "            flattened_data.append(entry)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "    \n",
    "    # Convert list columns to strings for CSV compatibility (optional)\n",
    "    df['sent_ids_list'] = df['sent_ids_list'].apply(lambda x: ','.join(map(str, x)))\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: ','.join(map(str, x)))\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = osp.join(data_root, dataset, f'{dataset}_{splitBy}_flattened.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {csv_path}\")\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Change these paths to match your setup\n",
    "    data_root = './data'\n",
    "    dataset = 'refclef'\n",
    "    splitBy = 'unc'\n",
    "    \n",
    "    df = convert_refer_to_df(data_root, dataset, splitBy)\n",
    "    print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
